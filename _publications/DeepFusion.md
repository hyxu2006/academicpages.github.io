---
title: "Deep Heterogeneous Feature Fusion for Template-Based Face Recognition"
collection: publications
permalink: /publications/DeepFusion
venue: "IEEE Winter Conference on Applications of Computer Vision (WACV), 2017."
date: 2017-2-15
citation: 'Navaneeth Bodla, Jingxiao Zheng, <b>Hongyu Xu</b>, Jun-Cheng Chen, Carlos Castillo and Rama Chellappa. <i>IEEE Winter Conference on Applications of Computer Vision</i>. <b>WACV 2017</b>.'
---
[[ArXiv]](https://arxiv.org/pdf/1702.04471.pdf) 


## Abstract
Although deep learning has yielded impressive performance for face recognition, many studies have shown that different networks learn different feature maps: while some networks are more receptive to pose and illumination others appear to capture more local information. Thus, in this work, we propose a deep heterogeneous feature fusion network to exploit the complementary information present in features generated by different deep convolutional neural networks (DCNNs) for template-based face recognition, where a template refers to a set of still face images or video frames from different sources which introduces more blur, pose, illumination and other variations than traditional face datasets. The proposed approach efficiently fuses the discriminative information of different deep features by 1) jointly learning the non-linear high-dimensional projection of the deep features and 2) generating a more discriminative template representation which preserves the inherent geometry of the deep features in the feature space. Experimental results on the IARPA Janus Challenge Set 3 (Janus CS3) dataset demonstrate that the proposed method can effectively improve the recognition performance. In addition, we also present a series of covariate experiments on the face verification task for in-depth qualitative evaluations for the proposed approach.
